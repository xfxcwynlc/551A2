{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#import 20newsgroups datasets from sklearn\n",
    "import numpy\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train',remove=(['headers','footers', 'quotes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "#list of categories(labels)\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(11314, 101631)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#counts the occurence of each word. \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape\n",
    "# count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#transform from occurrences to tf-idf \n",
    "#tf-idf: 1. Decide the number of occurrences of each word in a document by total number of words in document. (Term Frequences tf)\n",
    "#        2. It does another refinement. Downscaling weights for words that occurring in many documents.\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "#use X_train_tfidf to train the MODEL\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Do the normalization of X_train_counts, and it could be used later on.\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer_train = Normalizer().fit(X=X_train_counts)\n",
    "Xtraincounts_normalized = normalizer_train.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    " #   Training a classifier example:\n",
    " #   from sklearn.naive_bayes import MultinomialNB\n",
    " #   clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "    \n",
    " # Here we use decision trees\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train_tfidf, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Building a pipeline that behaves like a compound classifier\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "#text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),('dt', tree.DecisionTreeClassifier())])\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('norm', Normalizer()), ('dt', tree.DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Best n-gram range: (1, 2)\nBest use_idf: False\nBest criterion: gini\nBest max_depth: 95\n\nDecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n                       max_depth=95, max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort='deprecated',\n                       random_state=None, splitter='best')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Hyperparameter tuning using Randomized search\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "X = twenty_train.data\n",
    "Y = twenty_train.target\n",
    "# Create parameter for CountVectorizer\n",
    "ngram_range = [(1, 1), (1, 2), (2, 2)]\n",
    "# Create parameter for TfidfTransformer\n",
    "use_idf = (True, False)\n",
    "# Create lists of parameter for Decision Tree Classifier\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [45,65,95,125]\n",
    "#max_depth = [4,8,12]\n",
    "\n",
    "n = len(X)\n",
    "idx1 = numpy.arange(0, n, dtype=int)\n",
    "idx1_train, idx1_test = train_test_split(idx1, test_size=0.2, shuffle = True, random_state = 123)\n",
    "custom_cv = [(idx1_train, idx1_test)]\n",
    "\n",
    "# Create a dictionary of all the parameter options. We can access parameters of steps of a pipeline by using '__â€™\n",
    "parameters = dict(vect__ngram_range=ngram_range,\n",
    "                  tfidf__use_idf = use_idf,\n",
    "                      dt__criterion=criterion,\n",
    "                      dt__max_depth=max_depth);\n",
    "# Call RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(text_clf, parameters, n_iter=20, cv=custom_cv, random_state=199, return_train_score=False, \n",
    "                            n_jobs=-1)\n",
    "rs_clf.fit(X, Y)\n",
    "# View Best Parameters\n",
    "print('Best n-gram range:', rs_clf.best_estimator_.get_params()['vect__ngram_range'])\n",
    "print('Best use_idf:', rs_clf.best_estimator_.get_params()['tfidf__use_idf'])\n",
    "print('Best criterion:', rs_clf.best_estimator_.get_params()['dt__criterion'])\n",
    "print('Best max_depth:', rs_clf.best_estimator_.get_params()['dt__max_depth'])\n",
    "print(); print(rs_clf.best_estimator_.get_params()['dt'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#  Predict an outcome on new document:\n",
    "#  Doc_examples = ['God is love', 'GPU is fast']\n",
    "\n",
    "#  convert documents into tf-idf.  \n",
    "#  X_new_counts = count_vect.transform(Doc_examples) \n",
    "#  X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "\n",
    "#  predicted = clf.predict(X_new_tfidf)   (name_of_your_model_object)\n",
    "#  it stores the prediction of doc_examples.\n",
    "\n",
    "# Use Cross Validation To Evaluate Model\n",
    "#CV_Result = cross_val_score(rs_clf, X, Y, cv=4, n_jobs=-1)\n",
    "#print(); print('Cross validation result:',CV_Result)\n",
    "#print(); print('Mean of cross validation result:',CV_Result.mean())\n",
    "#print(); print('STDEV of cross validation result:',CV_Result.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.30      0.18      0.23       319\n           comp.graphics       0.34      0.42      0.38       389\n comp.os.ms-windows.misc       0.54      0.41      0.47       394\ncomp.sys.ibm.pc.hardware       0.44      0.29      0.35       392\n   comp.sys.mac.hardware       0.56      0.36      0.44       385\n          comp.windows.x       0.65      0.39      0.49       395\n            misc.forsale       0.61      0.52      0.56       390\n               rec.autos       0.15      0.67      0.24       396\n         rec.motorcycles       0.79      0.43      0.56       398\n      rec.sport.baseball       0.57      0.40      0.47       397\n        rec.sport.hockey       0.65      0.54      0.59       399\n               sci.crypt       0.69      0.43      0.53       396\n         sci.electronics       0.38      0.19      0.26       393\n                 sci.med       0.22      0.56      0.32       396\n               sci.space       0.66      0.38      0.48       394\n  soc.religion.christian       0.49      0.38      0.43       398\n      talk.politics.guns       0.40      0.37      0.38       364\n   talk.politics.mideast       0.82      0.44      0.57       376\n      talk.politics.misc       0.23      0.11      0.15       310\n      talk.religion.misc       0.19      0.14      0.16       251\n\n                accuracy                           0.39      7532\n               macro avg       0.48      0.38      0.40      7532\n            weighted avg       0.49      0.39      0.41      7532\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Let's see the prediction of the test set\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "twenty_test = fetch_20newsgroups(subset='test', remove=(['headers','footers', 'quotes']), shuffle=True)\n",
    "data_test = twenty_test.data\n",
    "predicted = rs_clf.predict(data_test)\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
    "#text_clf.fit(X,Y)\n",
    "#predicted = text_clf.predict(data_test)\n",
    "#print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}